# ETL with PySpark and AWS Glue (Simulation)

This project demonstrates a simplified **ETL pipeline** simulating an AWS Glue Job using **PySpark**.  
It processes a public dataset of movies, applies transformations, and writes results in **Parquet** format.

---

## ðŸš€ Steps
1. **Extract**: Load raw CSV dataset (movies).  
2. **Transform**: Filter movies released after 2000 and enrich with a rating category.  
3. **Load**: Save output as Parquet (simulating S3/Glue Data Catalog).  

---

## ðŸ—‚ Project Structure
